{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T20:41:04.452413Z",
     "start_time": "2017-12-30T20:41:04.350428Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gtsrb import batch_generator\n",
    "\n",
    "data = np.load('gtsrb_dataset.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File format\n",
    "\n",
    "**npz** is a simple archive zip archive made from numpy, similiar to a typical zip file.\n",
    "From this i can guess there are two files from the dataset. one file contains contains the \"test images\" and the other has \"train images\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What format does tensorflow want images\n",
    "[source](https://www.tensorflow.org/api_docs/python/tf/summary/image)\n",
    "\n",
    "The images are built from tensor which must be 4-D with shape [batch_size, height, width, channels] and where channels can be:\n",
    "\n",
    "1: tensor is interpreted as Grayscale.\n",
    "3: tensor is interpreted as RGB.\n",
    "4: tensor is interpreted as RGBA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch_generator function simplified\n",
    "\n",
    "* batch size - images per batch\n",
    "* chunk - a set of indices\n",
    "* batch generator function divides the groups the images into batches of (100)\n",
    "* x are the images\n",
    "* y is the label corresponding to the images.\n",
    "\n",
    "**The dataset**\n",
    "* Entire y training data returns an array of size (39209,43). I think 39209 is the no. of images and 43 is probably the feature vector (label for the image)\n",
    "* x training (with chunk) data returns an array of size (100, 32, 32, 3)\n",
    "    * 100 - chunk size (from batch_size).\n",
    "    * 32 32 is 32x32 vertically and horizontally (not sure which is which)\n",
    "    * 3 is the number of colour channels\n",
    "    * images are in the correct format 32x32x3 format\n",
    "* y training data (with chunk) returns an array (100, 43)\n",
    "    * 100 - chunk size (from batch_size)\n",
    "    * 43 is a binary feature vector \n",
    "---\n",
    "\n",
    "```python\n",
    "group = 'train'\n",
    "'y_{0:s}'.format(group) == 'y_train' # I assume this is the y training labels\n",
    "```\n",
    "\n",
    "```python\n",
    "# produce indices for the number of images\n",
    "indices = range(dataset_size)\n",
    "# shuffle these indices, essentially to pick out images in a random order\n",
    "np.random.shuffle(indices)\n",
    "```\n",
    "\n",
    "[slice](https://docs.python.org/2/library/functions.html#slice) returns the set of indices that are read only.\n",
    "The set is defined by the input (start, stop, step). The idea similar to linspace in matlab. It is used to select a specified range of the shuffled indices.\n",
    "\n",
    "\n",
    "```python\n",
    "dataset['X_{0:s}'.format(group)][chunk], dataset['y_{0:s}'.format(group)][chunk]\n",
    "```\n",
    "Accesses the training/testing images with the training/testing labels respectively\n",
    "\n",
    "\n",
    "```python\n",
    ">>> dataset['y_{0:s}'.format(group)][chunk][10, :]\n",
    "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]```\n",
    "this is a label for each image, it is a binary vector of length 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T20:41:05.129513Z",
     "start_time": "2017-12-30T20:41:04.457697Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# settings\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('log-frequency', 10,\n",
    "                            'Number of steps between logging results to the console and saving summaries.' +\n",
    "                            ' (default: %(default)d)')\n",
    "tf.app.flags.DEFINE_integer('flush-frequency', 50,\n",
    "                            'Number of steps between flushing summary results. (default: %(default)d)')\n",
    "tf.app.flags.DEFINE_integer('save-model-frequency', 100,\n",
    "                            'Number of steps between model saves. (default: %(default)d)')\n",
    "tf.app.flags.DEFINE_string('log-dir', '{cwd}/logs/'.format(cwd=os.getcwd()),\n",
    "                           'Directory where to write event logs and checkpoint. (default: %(default)s)')\n",
    "\n",
    "# Optimisation hyperparameters\n",
    "# for coding purposes set max_steps to a small value\n",
    "max_steps_real = 10000\n",
    "max_steps = 1000\n",
    "tf.app.flags.DEFINE_integer('max-steps', max_steps,\n",
    "                            'Number of mini-batches to train on. (default: %(default)d)')\n",
    "tf.app.flags.DEFINE_integer('batch-size', 100, 'Number of examples per mini-batch. (default: %(default)d)')\n",
    "tf.app.flags.DEFINE_float('learning-rate', 1e-3, 'Number of examples to run. (default: %(default)d)')\n",
    "tf.app.flags.DEFINE_integer('img-width', 32, 'Image width (default: %(default)d)')\n",
    "tf.app.flags.DEFINE_integer('img-height', 32, 'Image height (default: %(default)d)')\n",
    "tf.app.flags.DEFINE_integer('img-channels', 3, 'Image channels (default: %(default)d)')\n",
    "tf.app.flags.DEFINE_integer('num-classes', 43, 'Number of classes (default: %(default)d)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T20:46:52.573921Z",
     "start_time": "2017-12-30T20:46:52.568826Z"
    }
   },
   "outputs": [],
   "source": [
    "# each iteration returns a batch of (batch_size) images\n",
    "\n",
    "# code in main start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-31T08:35:48.019390Z",
     "start_time": "2017-12-31T08:35:47.984564Z"
    }
   },
   "outputs": [],
   "source": [
    "def deep_nn(x_image, class_count):\n",
    "    \"\"\" model for our CNN \"\"\"\n",
    "    # https://www.tensorflow.org/tutorials/layers \n",
    "\n",
    "\n",
    "    # first convolutional layer - maps on RBG image to 32 feature maps\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs = x_image,\n",
    "        filters = 32,\n",
    "        kernel_size = [5,5],\n",
    "        padding = 'same',\n",
    "        use_bias = False,\n",
    "        name='conv1'\n",
    "        )\n",
    "\n",
    "    # normalise batch\n",
    "    conv1_bn = tf.layers.batch_normalization(conv1, name='conv1_bn')\n",
    "    # apply activation \n",
    "    conv1_bn = tf.nn.relu(conv1_bn)\n",
    "\n",
    "    # pool layer 1\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "        inputs = conv1_bn,\n",
    "        pool_size = [2,2],\n",
    "        strides = 2,\n",
    "        name = 'pool1'\n",
    "        )\n",
    "\n",
    "    # convolutational layer 2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs = pool1,\n",
    "            filters = 64,\n",
    "            kernel_size = [5,5],\n",
    "            padding = 'same',\n",
    "            activation = tf.nn.relu,\n",
    "            use_bias = False,\n",
    "            name = 'conv2'\n",
    "            )\n",
    "\n",
    "    # normalise batch\n",
    "    conv2_bn = tf.layers.batch_normalization(conv2, name='conv2_bn')\n",
    "    # apply activation \n",
    "    conv2_bn = tf.nn.relu(conv2_bn)\n",
    "\n",
    "    # pool layer 2\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "            inputs = conv2_bn,\n",
    "            pool_size = [2,2],\n",
    "            strides = 2,\n",
    "            name = 'pool2'\n",
    "            )\n",
    "\n",
    "#     tf.Print(tf.shape(pool2), [x])\n",
    "#     tf.Print(pool2, [x])\n",
    "#     print(sess.run(tf.shape(pool2)))\n",
    "    \n",
    "    # dense layer, i'm not how to determine the size.\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64], name='pool2_flattened')\n",
    "    \n",
    "    # fully connected layer 1\n",
    "    # unit? look up\n",
    "    fc1 = tf.layers.dense(\n",
    "            inputs = pool2_flat,\n",
    "            activation = tf.nn.relu,\n",
    "            units = 1024,\n",
    "            name = 'fc1'\n",
    "            )\n",
    "    \n",
    "    # fully connected layer 2 and assigned as logits\n",
    "\n",
    "    logits = tf.layers.dense(\n",
    "            inputs = fc1,\n",
    "            units = class_count,\n",
    "            name = 'fc2'\n",
    "            )\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-31T08:46:36.938636Z",
     "start_time": "2017-12-31T08:46:36.400679Z"
    }
   },
   "outputs": [],
   "source": [
    "args.production = False\n",
    "\n",
    "# Generate batches\n",
    "for x_train, y_train in batch_generator(data, 'train'):\n",
    "    if not args.production:\n",
    "        x_image = x_train\n",
    "        y_train = y_train\n",
    "        # use one batch for building quicker\n",
    "        # run main\n",
    "        break\n",
    "    else:\n",
    "        # run main\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-31T08:46:47.168668Z",
     "start_time": "2017-12-31T08:46:47.000050Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    # clear graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.name_scope('input'):\n",
    "        \"\"\"build the computation graph by creating nodes for the input images and target output classes.\"\"\"\n",
    "        x = tf.placeholder(tf.float32, shape=[None, FLAGS.img_width * FLAGS.img_height * FLAGS.img_channels])\n",
    "        # for batch_size is dynamically computed based input values\n",
    "        x_image = tf.reshape(x, [-1, 32, 32, 3])\n",
    "        # what is class count, i think its the len of the vector\n",
    "        y_ = tf.placeholder(tf.float32, shape=[None, FLAGS.num_classes])\n",
    "\n",
    "        \"\"\"Â Here x and y_ aren't specific values. Rather, they are each a placeholder\n",
    "         -- a value that we'll input when we ask TensorFlow to run a computation.\"\"\"\n",
    "\n",
    "    with tf.variable_scope('model'):\n",
    "        # build graph\n",
    "        logits = deep_nn(x_image, FLAGS.num_classes)\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "main(_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "145px",
    "left": "836.082px",
    "right": "20px",
    "top": "133.991px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
